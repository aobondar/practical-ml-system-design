# Data Driven R&D

## 2.1 Key goal of R&D

Machine learning is not a guaranteed recipe for solving a problem. You essentially make the assumption that the given data contain patterns which can assist you in solving your task, and that a machine learning algorithm is capable of learn them. Around this fundamental question of "can it be solved by ML at all?" you also face a variety of choices in terms of architectures, feature engineering, hyperparameter tuning, and the overall system design. This places you in the realm of R&D rather than conventional engineering.

The good news is that often your business leader actually also wants to test a product hypothesis (as well as you need to test ML ones). For instance, that personalization generally leads to additional sales, or that by improving search quality, user retention within the service can be achieved. In this case, there is no need to separate technological hypotheses from business ones. And as we will see later, testing a business hypothesis often means going through all reasonable technical efforts within the scope that a business stakeholder is willing to invest. However, sometimes it's much cheaper to figure out how to test a business hypothesis without delving deep into technological R&D.

Your goal in that kind of project is to list all reasonable combinations of different approaches and parameters of solving a problem, order them in terms of expected gains, divided by complexity and run through them as quick as possible untill you meet your DoD.

When you list all your hypothesis your primary goal should be to narrow down the hypothesis space as quickly as possible. There are two key tools to help you do this:

* Accelerate iterations and rapidly work through the list of hypotheses.
* Conduct offline analytics to reduce the list of hypotheses.

In pratcice you usually combine these two methods in order to have the best results. Let's consider two big projects, and how to setup R&D process around them, and then we'll generalize all the tools we've used to achieve success.

## 2.2.1 Example 1: customer support chatbot

## 2.2.2 Example 2: recommendation system for UGC

## 2.2.3 Example 3: general purpose LLM-copilot for in-house enterprise usage

## 2.3 Key takeaways


What to cover:

- Narrowing down your hypothesis space and 'unknown zone' (on RAG and Agents examples). Recsys (on )
RAG: requests space? which type of index? what documents base? take existing or rewrite? summarizer? hyperparameters?
Recsys: are there good signals? what are the features? what is the model architecture?
LLM: can we do distributed training? do we have clean anough dataset? which data is required? ect
Search: ----
Agents: are working at all? Can we distignuish good and bad answers? Which model to take? Which tools?

Two ways for efficiency:
* reduce your hypothesys space by analytics (recsys - corellations, nlp - annotate examples)
* speed up you experiments cycle

Estimate and setup quick iteration speed. Fastest: online metrics with quick feedback, slow online metrics / slow criteria + fast offline. Slow online, slow release cycle, slow offline - not much experiments, makes sense to have something more straightforward. Fast experiments = more risky approaches.

What R&D roadmap is:
- hypothesis list (implement & run or analyze)
- improvements of experiments setup
- delivery to production
